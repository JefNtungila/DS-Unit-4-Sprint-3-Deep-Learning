{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LS_DS_Unit_4_Sprint_Challenge_3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "u4-s3-dnn",
      "language": "python",
      "display_name": "U4-S3-DNN (Python 3.7)"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "u4-s3-dnn"
    },
    "nteract": {
      "version": "0.14.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JefNtungila/DS-Unit-4-Sprint-3-Deep-Learning/blob/master/LS_DS_Unit_4_Sprint_Challenge_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McPAKwzwEuwj",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "# Major Neural Network Architectures Challenge\n",
        "## *Data Science Unit 4 Sprint 3 Challenge*\n",
        "\n",
        "In this sprint challenge, you'll explore some of the cutting edge of Data Science. This week we studied several famous neural network architectures: \n",
        "recurrent neural networks (RNNs), long short-term memory (LSTMs), convolutional neural networks (CNNs), and Generative Adverserial Networks (GANs). In this sprint challenge, you will revisit these models. Remember, we are testing your knowledge of these architectures not your ability to fit a model with high accuracy. \n",
        "\n",
        "__*Caution:*__  these approaches can be pretty heavy computationally. All problems were designed so that you should be able to achieve results within at most 5-10 minutes of runtime on Colab or a comparable environment. If something is running longer, doublecheck your approach!\n",
        "\n",
        "## Challenge Objectives\n",
        "*You should be able to:*\n",
        "* <a href=\"#p1\">Part 1</a>: Train a RNN classification model\n",
        "* <a href=\"#p2\">Part 2</a>: Utilize a pre-trained CNN for objective detection\n",
        "* <a href=\"#p3\">Part 3</a>: Describe the difference between a discriminator and generator in a GAN\n",
        "* <a href=\"#p4\">Part 4</a>: Describe yourself as a Data Science and elucidate your vision of AI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-5UwGRnJOmD4"
      },
      "source": [
        "<a id=\"p1\"></a>\n",
        "## Part 1 - RNNs\n",
        "\n",
        "Use an RNN to fit a multi-class classification model on reuters news articles to distinguish topics of articles. The data is already encoded properly for use in an RNN model. \n",
        "\n",
        "Your Tasks: \n",
        "- Use Keras to fit a predictive model, classifying news articles into topics. \n",
        "- Report your overall score and accuracy\n",
        "\n",
        "For reference, the [Keras IMDB sentiment classification example](https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py) will be useful, as well the RNN code we used in class.\n",
        "\n",
        "__*Note:*__  Focus on getting a running model, not on maxing accuracy with extreme data size or epoch numbers. Only revisit and push accuracy if you get everything else done!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmhWYPXgFKEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_QVSlFEAqWJM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "445de819-03bd-4679-f04a-ebc3e60bdd0a"
      },
      "source": [
        "# TODO - your code!\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding\n",
        "from keras.layers import LSTM"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQMZcla2E187",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np_load_old = np.load\n",
        "np.load = lambda *a, **k: np_load_old(*a, allow_pickle=True, **k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DS-9ksWjoJit",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets import reuters\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=None,\n",
        "                                                         skip_top=0,\n",
        "                                                         maxlen=None,\n",
        "                                                         test_split=0.2,\n",
        "                                                         seed=723812,\n",
        "                                                         start_char=1,\n",
        "                                                         oov_char=2,\n",
        "                                                         index_from=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fLKqFh8DovaN",
        "outputId": "1a718dd3-c06c-430d-8f45-146da51e29c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# Demo of encoding\n",
        "\n",
        "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
        "\n",
        "print(f\"Iran is encoded as {word_index['iran']} in the data\")\n",
        "print(f\"London is encoded as {word_index['london']} in the data\")\n",
        "print(\"Words are encoded as numbers in our dataset.\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iran is encoded as 779 in the data\n",
            "London is encoded as 544 in the data\n",
            "Words are encoded as numbers in our dataset.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol24kAD8O6gg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features = 20000\n",
        "# cut texts after this number of words (among top max_features most common words)\n",
        "maxlen = 80\n",
        "batch_size = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hvr4BxuUIJ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "a318bc27-0cb7-4786-907b-8fd2799c9a0c"
      },
      "source": [
        "# print('Pad sequences (samples x time)')\n",
        "# X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
        "# X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
        "print('x_train shape:', X_train.shape)\n",
        "print('x_test shape:', X_test.shape)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pad sequences (samples x time)\n",
            "x_train shape: (8982, 80)\n",
            "x_test shape: (2246, 80)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsAir_grUx-Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "393cd774-a07e-462a-e115-d0671d33a80b"
      },
      "source": [
        "print('Build model...')\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0823 16:33:23.082944 139849723418496 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0823 16:33:23.099108 139849723418496 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Build model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0823 16:33:23.392056 139849723418496 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0823 16:33:23.399908 139849723418496 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkfkSCDKU17e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "b303f48b-3680-4c5d-8687-0f0b59eb1490"
      },
      "source": [
        "# try using different optimizers and different optimizer configs\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0823 16:33:37.955615 139849723418496 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0823 16:33:37.983184 139849723418496 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0823 16:33:37.989211 139849723418496 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8D_buszOU5mx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "outputId": "bfe1ee10-3dbe-4151-86ca-5cd540d02cad"
      },
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "print('Train...')\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=15,\n",
        "          validation_data=(X_test, y_test))\n",
        "score, acc = model.evaluate(X_test, y_test,\n",
        "                            batch_size=batch_size)\n",
        "print('Test score:', score)\n",
        "print('Test accuracy:', acc)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train...\n",
            "Train on 8982 samples, validate on 2246 samples\n",
            "Epoch 1/15\n",
            "8982/8982 [==============================] - 36s 4ms/step - loss: -126.1316 - acc: 0.0499 - val_loss: -124.4585 - val_acc: 0.0396\n",
            "Epoch 2/15\n",
            "8982/8982 [==============================] - 36s 4ms/step - loss: -126.1316 - acc: 0.0499 - val_loss: -124.4585 - val_acc: 0.0396\n",
            "Epoch 3/15\n",
            "8982/8982 [==============================] - 36s 4ms/step - loss: -126.1316 - acc: 0.0499 - val_loss: -124.4585 - val_acc: 0.0396\n",
            "Epoch 4/15\n",
            "8982/8982 [==============================] - 36s 4ms/step - loss: -126.1316 - acc: 0.0499 - val_loss: -124.4585 - val_acc: 0.0396\n",
            "Epoch 5/15\n",
            "8982/8982 [==============================] - 36s 4ms/step - loss: -126.1316 - acc: 0.0499 - val_loss: -124.4585 - val_acc: 0.0396\n",
            "Epoch 6/15\n",
            "8982/8982 [==============================] - 36s 4ms/step - loss: -126.1316 - acc: 0.0499 - val_loss: -124.4585 - val_acc: 0.0396\n",
            "Epoch 7/15\n",
            "8982/8982 [==============================] - 36s 4ms/step - loss: -126.1316 - acc: 0.0499 - val_loss: -124.4585 - val_acc: 0.0396\n",
            "Epoch 8/15\n",
            "8982/8982 [==============================] - 36s 4ms/step - loss: -126.1316 - acc: 0.0499 - val_loss: -124.4585 - val_acc: 0.0396\n",
            "Epoch 9/15\n",
            "8982/8982 [==============================] - 36s 4ms/step - loss: -126.1316 - acc: 0.0499 - val_loss: -124.4585 - val_acc: 0.0396\n",
            "Epoch 10/15\n",
            "8982/8982 [==============================] - 36s 4ms/step - loss: -126.1316 - acc: 0.0499 - val_loss: -124.4585 - val_acc: 0.0396\n",
            "Epoch 11/15\n",
            "8982/8982 [==============================] - 35s 4ms/step - loss: -126.1316 - acc: 0.0499 - val_loss: -124.4585 - val_acc: 0.0396\n",
            "Epoch 12/15\n",
            "8982/8982 [==============================] - 36s 4ms/step - loss: -126.1316 - acc: 0.0499 - val_loss: -124.4585 - val_acc: 0.0396\n",
            "Epoch 13/15\n",
            "8982/8982 [==============================] - 36s 4ms/step - loss: -126.1316 - acc: 0.0499 - val_loss: -124.4585 - val_acc: 0.0396\n",
            "Epoch 14/15\n",
            "8982/8982 [==============================] - 36s 4ms/step - loss: -126.1316 - acc: 0.0499 - val_loss: -124.4585 - val_acc: 0.0396\n",
            "Epoch 15/15\n",
            "8982/8982 [==============================] - 36s 4ms/step - loss: -126.1316 - acc: 0.0499 - val_loss: -124.4585 - val_acc: 0.0396\n",
            "2246/2246 [==============================] - 2s 845us/step\n",
            "Test score: -124.4584993139931\n",
            "Test accuracy: 0.0396260017809439\n",
            "CPU times: user 11min 18s, sys: 35.3 s, total: 11min 53s\n",
            "Wall time: 8min 59s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yz0LCZd_O4IG"
      },
      "source": [
        "<a id=\"p2\"></a>\n",
        "## Part 2- CNNs\n",
        "\n",
        "### Find the Frog\n",
        "\n",
        "Time to play \"find the frog!\" Use Keras and ResNet50 (pre-trained) to detect which of the following images contain frogs:\n",
        "\n",
        "<img align=\"left\" src=\"https://d3i6fh83elv35t.cloudfront.net/newshour/app/uploads/2017/03/GettyImages-654745934-1024x687.jpg\" width=400>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "whIqEWR236Af",
        "outputId": "6f7ec564-f160-4b18-806c-78539dd62eed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!pip install google_images_download"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting google_images_download\n",
            "  Downloading https://files.pythonhosted.org/packages/18/ed/0319d30c48f3653802da8e6dcfefcea6370157d10d566ef6807cceb5ec4d/google_images_download-2.8.0.tar.gz\n",
            "Collecting selenium (from google_images_download)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n",
            "\u001b[K     |████████████████████████████████| 911kB 37.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium->google_images_download) (1.24.3)\n",
            "Building wheels for collected packages: google-images-download\n",
            "  Building wheel for google-images-download (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-images-download: filename=google_images_download-2.8.0-py2.py3-none-any.whl size=14547 sha256=2ca33d21bee61eccc44feb9855809cd0f76903baab414f9dc7057b989265f850\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/28/ad/f56e7061e1d2a9a1affe2f9c649c2570cb9198dd24ede0bbab\n",
            "Successfully built google-images-download\n",
            "Installing collected packages: selenium, google-images-download\n",
            "Successfully installed google-images-download-2.8.0 selenium-3.141.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EKnnnM8k38sN",
        "outputId": "a57056d0-0d65-4036-a7c1-46fcff25bd0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "from google_images_download import google_images_download\n",
        "\n",
        "response = google_images_download.googleimagesdownload()\n",
        "arguments = {\"keywords\": \"animal pond\", \"limit\": 5, \"print_urls\": True}\n",
        "absolute_image_paths = response.download(arguments)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Item no.: 1 --> Item name = animal pond\n",
            "Evaluating...\n",
            "Starting Download...\n",
            "Image URL: https://www.enchantedlearning.com/pgifs/Pondanimals.GIF\n",
            "Completed Image ====> 1.Pondanimals.GIF\n",
            "Image URL: https://i.ytimg.com/vi/NCbu0TND9vE/hqdefault.jpg\n",
            "Completed Image ====> 2.hqdefault.jpg\n",
            "Image URL: https://pklifescience.com/staticfiles/articles/images/PKLS4116_inline.png\n",
            "Completed Image ====> 3.PKLS4116_inline.png\n",
            "Image URL: https://pklifescience.com/staticfiles/articles/images/PKLS4116.png\n",
            "Completed Image ====> 4.PKLS4116.png\n",
            "Image URL: https://get.pxhere.com/photo/water-animal-pond-wildlife-mammal-fish-eat-fauna-whiskers-vertebrate-otter-mink-marmot-sea-otter-mustelidae-1383482.jpg\n",
            "Completed Image ====> 5.water-animal-pond-wildlife-mammal-fish-eat-fauna-whiskers-vertebrate-otter-mink-marmot-sea-otter-mustelidae-1383482.jpg\n",
            "\n",
            "Errors: 0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxRThP2RZTcu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "703df32b-dc8f-4610-e203-31a46a9bd06c"
      },
      "source": [
        "# Step 3 - Transform the images for DELF\n",
        "IMAGE_1_JPG = '1.Pondanimals.GIF'\n",
        "IMAGE_2_JPG = '2.hqdefault.jpg'\n",
        "IMAGE_3_JPG = '3.PKLS4116_inline.png'\n",
        "IMAGE_4_JPG = '4.PKLS4116.png'\n",
        "IMAGE_5_JPG = '5.water-animal-pond-wildlife-mammal-fish-eat-fauna-whiskers-vertebrate-otter-mink-marmot-sea-otter-mustelidae-1383482.jpg'\n",
        "\n",
        "def resize_image(filename, new_width=256, new_height=256):#the delf model was trained on images 256x256 the input of our model also should be 256x256\n",
        "  pil_image = Image.open(filename)\n",
        "  pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n",
        "  pil_image_rgb = pil_image.convert('RGB')\n",
        "  pil_image_rgb.save(filename, format='JPEG', quality=90)\n",
        "\n",
        "resize_image(IMAGE_1_JPG)\n",
        "resize_image(IMAGE_2_JPG)\n",
        "resize_image(IMAGE_3_JPG)\n",
        "resize_image(IMAGE_4_JPG)\n",
        "resize_image(IMAGE_5_JPG)\n",
        "\n",
        "def show_images(image_path_list):\n",
        "  plt.figure()\n",
        "  for i, image_path in enumerate(image_path_list):\n",
        "    plt.subplot(1, len(image_path_list), i+1)\n",
        "    plt.imshow(np.asarray(Image.open(image_path)))\n",
        "    plt.title(image_path)\n",
        "    plt.grid(False)\n",
        "    plt.yticks([])\n",
        "    plt.xticks([])\n",
        "  plt.show()\n",
        "\n",
        "show_images([IMAGE_1_JPG, IMAGE_2_JPG, IMAGE_3_JPG, IMAGE_4_JPG, IMAGE_5_JPG ])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-ddb7efce406e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# resize_image(IMAGE_1_JPG)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mresize_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMAGE_2_JPG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mresize_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMAGE_3_JPG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mresize_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMAGE_4_JPG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-ddb7efce406e>\u001b[0m in \u001b[0;36mresize_image\u001b[0;34m(filename, new_width, new_height)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mresize_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_height\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m#the delf model was trained on images 256x256 the input of our model also should be 256x256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mpil_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mpil_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageOps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpil_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnew_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mANTIALIAS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mpil_image_rgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Image' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "si5YfNqS50QU"
      },
      "source": [
        "At time of writing at least a few do, but since the Internet changes - it is possible your 5 won't. You can easily verify yourself, and (once you have working code) increase the number of images you pull to be more sure of getting a frog. Your goal is to validly run ResNet50 on the input images - don't worry about tuning or improving the model.\n",
        "\n",
        "*Hint* - ResNet 50 doesn't just return \"frog\". The three labels it has for frogs are: `bullfrog, tree frog, tailed frog`\n",
        "\n",
        "*Stretch goal* - also check for fish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FaT07ddW3nHz",
        "colab": {}
      },
      "source": [
        "# TODO - your code!\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XEuhvSu7O5Rf"
      },
      "source": [
        "<a id=\"p3\"></a>\n",
        "## Part 3 - Autoencoders\n",
        "\n",
        "Describe a use case for an autoencoder given that an autoencoder tries to predict its own input. \n",
        "\n",
        "__*Your Answer:*__ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dOfflVkXJUa",
        "colab_type": "text"
      },
      "source": [
        "#Autoencoders are really useful in trying to label data / unsupervised feature engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "626zYgjkO7Vq"
      },
      "source": [
        "<a id=\"p4\"></a>\n",
        "## Part 4 - More..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "__lDWfcUO8oo"
      },
      "source": [
        "Answer the following questions, with a target audience of a fellow Data Scientist:\n",
        "\n",
        "- What do you consider your strongest area, as a Data Scientist?\n",
        "- What area of Data Science would you most like to learn more about, and why?\n",
        "- Where do you think Data Science will be in 5 years?\n",
        "- What are the threats posed by AI to our society?\n",
        "- How do you think we can counteract those threats? \n",
        "- Do you think achieving General Artifical Intelligence is ever possible?\n",
        "\n",
        "A few sentences per answer is fine - only elaborate if time allows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAABDOtPV-Qt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1 -I have very strong problems skills and can create methods to solve problems even if I haven't seen them before.\n",
        "# 2 -Coming from a non-software, but engineering background I need to work really hard on my coding skills. I also need to improve my local workflow although I disdain it.\n",
        "# 3 - Inevitable\n",
        "# 4 - I consider AI a tool and a tool is only as good as what people make about it\n",
        "# 5 - Educate people?\n",
        "# 6 - That's building the tower of Babel, but the technical engineering skills were definitely there to build it."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_Hoqe3mM_Mtc"
      },
      "source": [
        "## Congratulations! \n",
        "\n",
        "Thank you for your hard work, and congratulations! You've learned a lot, and you should proudly call yourself a Data Scientist.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVZMLbh4Euw5",
        "colab_type": "code",
        "outputId": "4ef5b82e-4e2b-452b-bd34-9b7342e89cc9",
        "colab": {}
      },
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>\"\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    }
  ]
}